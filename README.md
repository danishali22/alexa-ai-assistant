ğŸ¤– Alexa-Style Multimodal AI Assistant
An advanced **multimodal personal AI assistant** that combines **voice, vision, and text** to create an experience similar to Alexa â€” but smarter. You can **talk to it, show it things through your webcam, and even call it in video form**.

---

ğŸ“Œ Features

* ğŸ™ï¸ **Voice Input & Transcription**: Converts speech into text using SpeechRecognition + PyAudio.
* ğŸ‘€ **Webcam & Vision Analysis**: Detects shirt colors, gestures, facial expressions, and objects via OpenCV.
* ğŸ§  **Agentic RAG**: Handles knowledge retrieval and multi-turn Q\&A with LangGraph + Groq.
* ğŸ”Š **Text-to-Speech (TTS)**: Human-like responses using ElevenLabs and gTTS.
* ğŸŒ **Multimodal Interface**: Seamlessly supports text, voice, and webcam inputs.
* ğŸ–¥ï¸ **Gradio UI**: Interactive web interface for real-time conversations.

---

ğŸ› ï¸ Tech Stack

| Category             | Tools & Services         |
| -------------------- | ------------------------ |
| Programming Language | Python                   |
| UI Framework         | Gradio                   |
| Speech-to-Text       | SpeechRecognition + Groq |
| Vision               | OpenCV                   |
| Text-to-Speech (TTS) | ElevenLabs, gTTS         |
| AI & Orchestration   | LangGraph, Google GenAI  |
| Environment Handling | python-dotenv            |
| Runtime & Packaging  | uv                       |

---

ğŸ“ Project Structure

```
â””â”€â”€ danishali22-alexa-ai-assistant/
    â”œâ”€â”€ README.md                # Project documentation
    â”œâ”€â”€ ai_agent.py              # Agentic RAG + assistant logic
    â”œâ”€â”€ main.py                  # Entry point with Gradio UI
    â”œâ”€â”€ pyproject.toml           # Project dependencies & config
    â”œâ”€â”€ speech_to_text.py        # Speech-to-text pipeline
    â”œâ”€â”€ text_to_speech.py        # TTS functions (ElevenLabs + gTTS)
    â”œâ”€â”€ tools.py                 # Utility functions (API calls, env)
    â”œâ”€â”€ webcam_utils.py          # Webcam capture & analysis
    â”œâ”€â”€ .python-version          # Python runtime version
    â””â”€â”€ .gradio/
        â””â”€â”€ certificate.pem      # SSL certificate for Gradio
```

---

ğŸ”§ Setup Instructions

**Clone the Repository**

```bash
git clone https://github.com/danishali22/danishali22-alexa-ai-assistant.git
cd danishali22-alexa-ai-assistant
```

**Install Dependencies**

```bash
uv pip install -r pyproject.toml
```

**Configure Environment Variables**

```bash
cp .env.example .env
# Fill in your API keys (Groq, ElevenLabs, etc.)
```

**Run the App**

```bash
python main.py
```

---

ğŸ¤– How It Works

1. User interacts via text, voice, or webcam.
2. Voice input is transcribed with SpeechRecognition + Groq.
3. Webcam frames are processed with OpenCV for visual understanding.
4. Knowledge-based responses are generated using Agentic RAG.
5. Replies are returned as text + natural speech (ElevenLabs/gTTS).

---

ğŸ“š What I Learned

* Building **multimodal AI** (voice + vision + text)
* Integrating **Groq, LangGraph, and Google GenAI**
* Real-time speech recognition & synthesis
* Creating a smooth **Gradio-powered interface**
* Managing complex dependencies with **uv**

---

ğŸ™Œ Feedback
If you find this project interesting or want to collaborate, feel free to open an issue or connect!

GitHub: [danishali22](https://github.com/danishali22)
